{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a4a57e",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5bb03a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\fikri\\appdata\\roaming\\python\\python39\\site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\fikri\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f6e73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f27d94e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pengujian', 0.7212876677513123), ('uji', 0.7056494951248169), ('pemeriksaan', 0.6564321517944336), ('ujian', 0.5918323993682861), ('percobaan', 0.5823646187782288), ('eksperimen', 0.5750775933265686), ('test', 0.550246000289917), ('serologis', 0.5315841436386108), ('verifikasi', 0.5280280113220215), ('ujicoba', 0.5256417393684387)]\n"
     ]
    }
   ],
   "source": [
    "# Gensim import dan load pre-trained idwiki language model\n",
    "\n",
    "path = '../id_wiki/idwiki_word2vec_300.model'\n",
    "id_w2v = gensim.models.word2vec.Word2Vec.load(path)\n",
    "print(id_w2v.wv.most_similar('tes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41a1b1",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89787624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jenis</th>\n",
       "      <th>uraian</th>\n",
       "      <th>pertanyaan</th>\n",
       "      <th>opsi1</th>\n",
       "      <th>opsi2</th>\n",
       "      <th>opsi3</th>\n",
       "      <th>opsi4</th>\n",
       "      <th>kunci_jawaban</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Makna kata/istilah</td>\n",
       "      <td>Padi yang luas menguning adalah hasil tanam ya...</td>\n",
       "      <td>Makna kata jasa pada paragraf di atas adalah</td>\n",
       "      <td>Pelayanan yang terbaik bagi kita.\\t</td>\n",
       "      <td>Manfaat yang melimpah bagi kita\\t</td>\n",
       "      <td>Perbuatan yang berguna bagi orang lain\\t</td>\n",
       "      <td>Jerih payah yang sangat menguntungkan</td>\n",
       "      <td>Perbuatan yang berguna bagi orang lain\\t</td>\n",
       "      <td>Mudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antonim/sinonim</td>\n",
       "      <td>Suara radio tetangga sebelah sangat keras pada...</td>\n",
       "      <td>Antonim kata keras pada kalimat tersebut adalah</td>\n",
       "      <td>pelan\\t</td>\n",
       "      <td>lunak\\t</td>\n",
       "      <td>kaku\\t</td>\n",
       "      <td>kencang</td>\n",
       "      <td>pelan\\t</td>\n",
       "      <td>Mudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Informasi tersurat teks</td>\n",
       "      <td>Pembiasaan Hidup Sehat Sejak KecilPola hidup s...</td>\n",
       "      <td>Bagaimana cara memenuhi gizi anak pada usia ba...</td>\n",
       "      <td>Menambah gizi anak seiring bertambahnya usia a...</td>\n",
       "      <td>Makan makanan bergizi, istirahat cukup, dan ol...</td>\n",
       "      <td>Mempunyai kekebalan yang baik terhadap seranga...</td>\n",
       "      <td>Pemenuhan gizi dengan pemberian ASI saat anak...</td>\n",
       "      <td>Pemenuhan gizi dengan pemberian ASI saat anak...</td>\n",
       "      <td>Sedang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Informasi tersirat teks</td>\n",
       "      <td>Mulai tahun 2016 kuota haji di Indonesssia dit...</td>\n",
       "      <td>Berdasarkan data kuota jumlah jamaah haji untu...</td>\n",
       "      <td>77</td>\n",
       "      <td>77.7</td>\n",
       "      <td>78</td>\n",
       "      <td>77,800</td>\n",
       "      <td>77</td>\n",
       "      <td>Sedang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Informasi tersurat teks</td>\n",
       "      <td>Kebiasaan makan makanan bergizi dengan kadar s...</td>\n",
       "      <td>Kalimat dalam paragraf di atas yang tidak padu...</td>\n",
       "      <td>Kebutuhan gizi anak akan semakin bertambah sei...</td>\n",
       "      <td>Kebutuhan gizi anak baru terpenuhi saat anak b...</td>\n",
       "      <td>Tubuh anak mudah terserang berbagai macam peny...</td>\n",
       "      <td>Pertumbuhan dan perkembangan anak akan semakin...</td>\n",
       "      <td>Tubuh anak mudah terserang berbagai macam peny...</td>\n",
       "      <td>Sedang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     jenis                                             uraian  \\\n",
       "0       Makna kata/istilah  Padi yang luas menguning adalah hasil tanam ya...   \n",
       "1          Antonim/sinonim  Suara radio tetangga sebelah sangat keras pada...   \n",
       "2  Informasi tersurat teks  Pembiasaan Hidup Sehat Sejak KecilPola hidup s...   \n",
       "3  Informasi tersirat teks  Mulai tahun 2016 kuota haji di Indonesssia dit...   \n",
       "4  Informasi tersurat teks  Kebiasaan makan makanan bergizi dengan kadar s...   \n",
       "\n",
       "                                          pertanyaan  \\\n",
       "0       Makna kata jasa pada paragraf di atas adalah   \n",
       "1    Antonim kata keras pada kalimat tersebut adalah   \n",
       "2  Bagaimana cara memenuhi gizi anak pada usia ba...   \n",
       "3  Berdasarkan data kuota jumlah jamaah haji untu...   \n",
       "4  Kalimat dalam paragraf di atas yang tidak padu...   \n",
       "\n",
       "                                               opsi1  \\\n",
       "0                Pelayanan yang terbaik bagi kita.\\t   \n",
       "1                                            pelan\\t   \n",
       "2  Menambah gizi anak seiring bertambahnya usia a...   \n",
       "3                                                 77   \n",
       "4  Kebutuhan gizi anak akan semakin bertambah sei...   \n",
       "\n",
       "                                               opsi2  \\\n",
       "0                  Manfaat yang melimpah bagi kita\\t   \n",
       "1                                            lunak\\t   \n",
       "2  Makan makanan bergizi, istirahat cukup, dan ol...   \n",
       "3                                               77.7   \n",
       "4  Kebutuhan gizi anak baru terpenuhi saat anak b...   \n",
       "\n",
       "                                               opsi3  \\\n",
       "0           Perbuatan yang berguna bagi orang lain\\t   \n",
       "1                                             kaku\\t   \n",
       "2  Mempunyai kekebalan yang baik terhadap seranga...   \n",
       "3                                                 78   \n",
       "4  Tubuh anak mudah terserang berbagai macam peny...   \n",
       "\n",
       "                                               opsi4  \\\n",
       "0              Jerih payah yang sangat menguntungkan   \n",
       "1                                            kencang   \n",
       "2   Pemenuhan gizi dengan pemberian ASI saat anak...   \n",
       "3                                             77,800   \n",
       "4  Pertumbuhan dan perkembangan anak akan semakin...   \n",
       "\n",
       "                                       kunci_jawaban kategori  \n",
       "0           Perbuatan yang berguna bagi orang lain\\t    Mudah  \n",
       "1                                            pelan\\t    Mudah  \n",
       "2   Pemenuhan gizi dengan pemberian ASI saat anak...   Sedang  \n",
       "3                                                 77   Sedang  \n",
       "4  Tubuh anak mudah terserang berbagai macam peny...   Sedang  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prepare Dataset\n",
    "yelp = pd.read_csv('dataset.csv', sep=',', header = 0)\n",
    "del yelp['No']\n",
    "yelp = yelp.dropna()\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e59d6551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jenis</th>\n",
       "      <th>uraian</th>\n",
       "      <th>pertanyaan</th>\n",
       "      <th>opsi1</th>\n",
       "      <th>opsi2</th>\n",
       "      <th>opsi3</th>\n",
       "      <th>opsi4</th>\n",
       "      <th>kunci_jawaban</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Makna kata/istilah</td>\n",
       "      <td>Padi yang luas menguning adalah hasil tanam ya...</td>\n",
       "      <td>Makna kata jasa pada paragraf di atas adalah</td>\n",
       "      <td>Pelayanan yang terbaik bagi kita.</td>\n",
       "      <td>Manfaat yang melimpah bagi kita</td>\n",
       "      <td>Perbuatan yang berguna bagi orang lain</td>\n",
       "      <td>Jerih payah yang sangat menguntungkan</td>\n",
       "      <td>Perbuatan yang berguna bagi orang lain</td>\n",
       "      <td>Mudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antonim/sinonim</td>\n",
       "      <td>Suara radio tetangga sebelah sangat keras pada...</td>\n",
       "      <td>Antonim kata keras pada kalimat tersebut adalah</td>\n",
       "      <td>pelan</td>\n",
       "      <td>lunak</td>\n",
       "      <td>kaku</td>\n",
       "      <td>kencang</td>\n",
       "      <td>pelan</td>\n",
       "      <td>Mudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Informasi tersurat teks</td>\n",
       "      <td>Pembiasaan Hidup Sehat Sejak KecilPola hidup s...</td>\n",
       "      <td>Bagaimana cara memenuhi gizi anak pada usia ba...</td>\n",
       "      <td>Menambah gizi anak seiring bertambahnya usia a...</td>\n",
       "      <td>Makan makanan bergizi, istirahat cukup, dan ol...</td>\n",
       "      <td>Mempunyai kekebalan yang baik terhadap seranga...</td>\n",
       "      <td>Pemenuhan gizi dengan pemberian ASI saat anak...</td>\n",
       "      <td>Pemenuhan gizi dengan pemberian ASI saat anak...</td>\n",
       "      <td>Sedang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Informasi tersirat teks</td>\n",
       "      <td>Mulai tahun 2016 kuota haji di Indonesssia dit...</td>\n",
       "      <td>Berdasarkan data kuota jumlah jamaah haji untu...</td>\n",
       "      <td>77</td>\n",
       "      <td>77.7</td>\n",
       "      <td>78</td>\n",
       "      <td>77,800</td>\n",
       "      <td>77</td>\n",
       "      <td>Sedang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Informasi tersurat teks</td>\n",
       "      <td>Kebiasaan makan makanan bergizi dengan kadar s...</td>\n",
       "      <td>Kalimat dalam paragraf di atas yang tidak padu...</td>\n",
       "      <td>Kebutuhan gizi anak akan semakin bertambah sei...</td>\n",
       "      <td>Kebutuhan gizi anak baru terpenuhi saat anak b...</td>\n",
       "      <td>Tubuh anak mudah terserang berbagai macam peny...</td>\n",
       "      <td>Pertumbuhan dan perkembangan anak akan semakin...</td>\n",
       "      <td>Tubuh anak mudah terserang berbagai macam peny...</td>\n",
       "      <td>Sedang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     jenis                                             uraian  \\\n",
       "0       Makna kata/istilah  Padi yang luas menguning adalah hasil tanam ya...   \n",
       "1          Antonim/sinonim  Suara radio tetangga sebelah sangat keras pada...   \n",
       "2  Informasi tersurat teks  Pembiasaan Hidup Sehat Sejak KecilPola hidup s...   \n",
       "3  Informasi tersirat teks  Mulai tahun 2016 kuota haji di Indonesssia dit...   \n",
       "4  Informasi tersurat teks  Kebiasaan makan makanan bergizi dengan kadar s...   \n",
       "\n",
       "                                          pertanyaan  \\\n",
       "0       Makna kata jasa pada paragraf di atas adalah   \n",
       "1    Antonim kata keras pada kalimat tersebut adalah   \n",
       "2  Bagaimana cara memenuhi gizi anak pada usia ba...   \n",
       "3  Berdasarkan data kuota jumlah jamaah haji untu...   \n",
       "4  Kalimat dalam paragraf di atas yang tidak padu...   \n",
       "\n",
       "                                               opsi1  \\\n",
       "0                  Pelayanan yang terbaik bagi kita.   \n",
       "1                                              pelan   \n",
       "2  Menambah gizi anak seiring bertambahnya usia a...   \n",
       "3                                                 77   \n",
       "4  Kebutuhan gizi anak akan semakin bertambah sei...   \n",
       "\n",
       "                                               opsi2  \\\n",
       "0                    Manfaat yang melimpah bagi kita   \n",
       "1                                              lunak   \n",
       "2  Makan makanan bergizi, istirahat cukup, dan ol...   \n",
       "3                                               77.7   \n",
       "4  Kebutuhan gizi anak baru terpenuhi saat anak b...   \n",
       "\n",
       "                                               opsi3  \\\n",
       "0             Perbuatan yang berguna bagi orang lain   \n",
       "1                                               kaku   \n",
       "2  Mempunyai kekebalan yang baik terhadap seranga...   \n",
       "3                                                 78   \n",
       "4  Tubuh anak mudah terserang berbagai macam peny...   \n",
       "\n",
       "                                               opsi4  \\\n",
       "0              Jerih payah yang sangat menguntungkan   \n",
       "1                                            kencang   \n",
       "2   Pemenuhan gizi dengan pemberian ASI saat anak...   \n",
       "3                                             77,800   \n",
       "4  Pertumbuhan dan perkembangan anak akan semakin...   \n",
       "\n",
       "                                       kunci_jawaban kategori  \n",
       "0             Perbuatan yang berguna bagi orang lain    Mudah  \n",
       "1                                              pelan    Mudah  \n",
       "2   Pemenuhan gizi dengan pemberian ASI saat anak...   Sedang  \n",
       "3                                                 77   Sedang  \n",
       "4  Tubuh anak mudah terserang berbagai macam peny...   Sedang  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "yelp = yelp.replace('\\n',' ', regex=True)\n",
    "yelp = yelp.replace('\\t','', regex=True)\n",
    "yelp = yelp.replace('\"',' \" ', regex=True)\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e3fc59d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  teks kategori\n",
      "0    Makna kata/istilah Padi yang luas menguning ad...    Mudah\n",
      "1    Antonim/sinonim Suara radio tetangga sebelah s...    Mudah\n",
      "2    Informasi tersurat teks Pembiasaan Hidup Sehat...   Sedang\n",
      "3    Informasi tersirat teks Mulai tahun 2016 kuota...   Sedang\n",
      "4    Informasi tersurat teks Kebiasaan makan makana...   Sedang\n",
      "..                                                 ...      ...\n",
      "413  Tanda baca Merdeka, merdeka!  \" Teruskan geril...    Mudah\n",
      "414  Kata bentukan Tebing Breksi adalah salah satu ...    Sulit\n",
      "415  Tanda baca  \" Sebaiknya kita membawa buah tang...    Mudah\n",
      "416  Istilah/kata Permasalahan yang dihadapi Nia se...    Sulit\n",
      "417  Tanda baca Joya berkata,  \" Wow, Alangkah inda...    Mudah\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "#Kolom teks merupakan gabungan dari kolom jenis soal, uraian soal, pertanyaan soal, opsi1 soal, opsi2 soal, opsi3 soal, opsi4 soal, dan kunci jawaban soal\n",
    "df['teks'] = yelp['jenis'].map(str) + ' ' + yelp['uraian'].map(str)+ ' ' + yelp['pertanyaan'].map(str)+ ' ' + yelp['opsi1'].map(str)+ ' ' + yelp['opsi2'].map(str)+ ' ' + yelp['opsi3'].map(str)+ ' ' + yelp['opsi4'].map(str)+ ' ' + yelp['kunci_jawaban'].map(str)\n",
    "\n",
    "#kolom kategori merupakan kolom kategori kesulitan soal\n",
    "df['kategori'] = yelp['kategori']\n",
    "\n",
    "yelp = yelp.dropna()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b972a0",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e2c0985",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fikri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763c054",
   "metadata": {},
   "source": [
    "## Stopwords & Embedding Vectorization(Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "572f179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fikri\\AppData\\Local\\Temp/ipykernel_5920/1651433560.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  for doc in yelp['pertanyaan'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(418, 300)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pembentukan dataframe untuk vektorisasi embedding\n",
    "\n",
    "docs_vectors = pd.DataFrame() # creating empty final dataframe\n",
    "stopwords = nltk.corpus.stopwords.words('indonesian') # removing stop words\n",
    "for doc in yelp['pertanyaan'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
    "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
    "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
    "        if word not in stopwords: # if word is not present in stopwords then (try)\n",
    "            try:\n",
    "                word_vec = id_w2v.wv[word] # if word is present in embeddings(id_wikidata(300)) then proceed\n",
    "                temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
    "            except:\n",
    "                pass\n",
    "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
    "    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n",
    "docs_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48f785a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pengecekan terhadap null values pada dataframe docs_vector\n",
    "\n",
    "pd.isnull(docs_vectors).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2adb95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformasi kolom kategori yang semula teks menuju bentuk angka\n",
    "\n",
    "df['kategori'] = df['kategori'].astype(\"category\")\n",
    "docs_vectors['label'] = df['kategori'].cat.codes\n",
    "docs_vectors = docs_vectors.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235239d",
   "metadata": {},
   "source": [
    "# Generate CSV Dataset for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88c764da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for evauation successfully generated !\n"
     ]
    }
   ],
   "source": [
    "docs_vectors.to_csv('dataset_eval_w2v.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Dataset for evauation successfully generated !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f80728",
   "metadata": {},
   "source": [
    "# Train & Test Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "faf8b3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((355, 300), (355,), (63, 300), (63,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Persiapan evaluasi - split dataset dan pemilihan teknik classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df_eval = dataset = pd.read_csv('dataset_eval_w2v.csv', header=0, engine='python')\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_eval.drop('label', axis = 1),\n",
    "                                                   df_eval['label'],\n",
    "                                                   test_size = 0.15, random_state=42)\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cede3",
   "metadata": {},
   "source": [
    "# Single Fold Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aae5c46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluasi akurasi klasifikasi\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300)\n",
    "model.fit(train_x, train_y)\n",
    "test_pred = model.predict(test_x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "51582ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted y\n",
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "401d115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Mudah       0.73      0.92      0.81        24\n",
      "      Sedang       0.45      0.38      0.42        13\n",
      "       Sulit       0.68      0.58      0.62        26\n",
      "\n",
      "    accuracy                           0.67        63\n",
      "   macro avg       0.62      0.63      0.62        63\n",
      "weighted avg       0.65      0.67      0.65        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(test_y, y_pred, target_names=['Mudah', 'Sedang', 'Sulit']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd3afca",
   "metadata": {},
   "source": [
    "# Machine Learning Classification Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b6173",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48d5283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6706304967174533 | REC : 0.6762820512820512 | F1-SCORE : 0.67168405823868 | SUPP : None\n",
      "Fold 2 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6476068376068377 | REC : 0.6517094017094017 | F1-SCORE : 0.6488888888888887 | SUPP : None\n",
      "Fold 3 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6581196581196581 | REC : 0.6645299145299145 | F1-SCORE : 0.6605128205128206 | SUPP : None\n",
      "Fold 4 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6476068376068377 | REC : 0.6517094017094017 | F1-SCORE : 0.6488888888888887 | SUPP : None\n",
      "Fold 5 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6625641025641026 | REC : 0.6634615384615384 | F1-SCORE : 0.6622222222222223 | SUPP : None\n",
      "Fold 6 Eval...   | ACC : 0.7301587301587301 | PREC : 0.6753246753246754 | REC : 0.6784188034188036 | F1-SCORE : 0.6737606837606838 | SUPP : None\n",
      "Fold 7 Eval...   | ACC : 0.6825396825396826 | PREC : 0.6368376068376068 | REC : 0.6378205128205128 | F1-SCORE : 0.636996336996337 | SUPP : None\n",
      "Fold 8 Eval...   | ACC : 0.7301587301587301 | PREC : 0.6754657687991021 | REC : 0.6784188034188036 | F1-SCORE : 0.6748366013071897 | SUPP : None\n",
      "Fold 9 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6497867564534231 | REC : 0.6517094017094017 | F1-SCORE : 0.6486928104575163 | SUPP : None\n",
      "Fold 10 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6466049382716049 | REC : 0.6517094017094017 | F1-SCORE : 0.6475816993464053 | SUPP : None\n",
      "Average Accuracy Score(10 Times Evaluation) : 0.7031746031746032\n",
      "Average Precision Score(10 Times Evaluation) : 0.6570547678301304\n",
      "Average Recall Score(10 Times Evaluation) : 0.6605769230769231\n",
      "Average F1 Score(10 Times Evaluation) : 0.6574065010619632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "acc_temp = 0\n",
    "prec_temp = 0\n",
    "rec_temp = 0\n",
    "f1_temp = 0\n",
    "n_fold = 10\n",
    "\n",
    "for i in range(n_fold):\n",
    "    model = RandomForestClassifier(n_estimators = 300)\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    test_pred = model.predict(test_x)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    temp_res = accuracy_score(test_y, test_pred)\n",
    "    acc_temp+= temp_res\n",
    "    \n",
    "    precision, recall, f_value, support = precision_recall_fscore_support(test_y, test_pred, average='macro')\n",
    "    \n",
    "    prec_temp+=precision\n",
    "    rec_temp += recall\n",
    "    f1_temp += f_value\n",
    "    \n",
    "    print(f'Fold {i+1} Eval...   | ACC : {temp_res} | PREC : {precision} | REC : {recall} | F1-SCORE : {f_value} | SUPP : {support}')\n",
    "\n",
    "res = acc_temp/n_fold\n",
    "prec_res = prec_temp/n_fold\n",
    "rec_res = rec_temp/n_fold\n",
    "f1_res = f1_temp/n_fold\n",
    "\n",
    "print(f'Average Accuracy Score({n_fold} Times Evaluation) : {res}')\n",
    "print(f'Average Precision Score({n_fold} Times Evaluation) : {prec_res}')\n",
    "print(f'Average Recall Score({n_fold} Times Evaluation) : {rec_res}')\n",
    "print(f'Average F1 Score({n_fold} Times Evaluation) : {f1_res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f64a84",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4d43a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 2 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 3 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 4 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 5 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 6 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 7 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 8 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 9 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Fold 10 Eval...   | ACC : 0.6031746031746031 | PREC : 0.5816239316239317 | REC : 0.5844017094017094 | F1-SCORE : 0.5768198521821711 | SUPP : None\n",
      "Average Accuracy Score(10 Times Evaluation) : 0.603174603174603\n",
      "Average Precision Score(10 Times Evaluation) : 0.5816239316239316\n",
      "Average Recall Score(10 Times Evaluation) : 0.5844017094017094\n",
      "Average F1 Score(10 Times Evaluation) : 0.5768198521821712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "acc_temp = 0\n",
    "prec_temp = 0\n",
    "rec_temp = 0\n",
    "f1_temp = 0\n",
    "n_fold = 10\n",
    "\n",
    "for i in range(n_fold):\n",
    "    model = GaussianNB()\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    test_pred = model.predict(test_x)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    temp_res = accuracy_score(test_y, test_pred)\n",
    "    acc_temp+= temp_res\n",
    "    \n",
    "    precision, recall, f_value, support = precision_recall_fscore_support(test_y, test_pred, average='macro')\n",
    "    \n",
    "    prec_temp+=precision\n",
    "    rec_temp += recall\n",
    "    f1_temp += f_value\n",
    "    \n",
    "    print(f'Fold {i+1} Eval...   | ACC : {temp_res} | PREC : {precision} | REC : {recall} | F1-SCORE : {f_value} | SUPP : {support}')\n",
    "\n",
    "res = acc_temp/n_fold\n",
    "prec_res = prec_temp/n_fold\n",
    "rec_res = rec_temp/n_fold\n",
    "f1_res = f1_temp/n_fold\n",
    "\n",
    "print(f'Average Accuracy Score({n_fold} Times Evaluation) : {res}')\n",
    "print(f'Average Precision Score({n_fold} Times Evaluation) : {prec_res}')\n",
    "print(f'Average Recall Score({n_fold} Times Evaluation) : {rec_res}')\n",
    "print(f'Average F1 Score({n_fold} Times Evaluation) : {f1_res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1140b6",
   "metadata": {},
   "source": [
    "## SVM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c992efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 2 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 3 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 4 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 5 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 6 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 7 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 8 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 9 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Fold 10 Eval...   | ACC : 0.5873015873015873 | PREC : 0.5520202020202021 | REC : 0.547008547008547 | F1-SCORE : 0.5382659547419274 | SUPP : None\n",
      "Average Accuracy Score(10 Times Evaluation) : 0.5873015873015872\n",
      "Average Precision Score(10 Times Evaluation) : 0.5520202020202021\n",
      "Average Recall Score(10 Times Evaluation) : 0.547008547008547\n",
      "Average F1 Score(10 Times Evaluation) : 0.5382659547419274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "acc_temp = 0\n",
    "prec_temp = 0\n",
    "rec_temp = 0\n",
    "f1_temp = 0\n",
    "n_fold = 10\n",
    "\n",
    "for i in range(n_fold):\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    test_pred = model.predict(test_x)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    temp_res = accuracy_score(test_y, test_pred)\n",
    "    acc_temp+= temp_res\n",
    "    \n",
    "    precision, recall, f_value, support = precision_recall_fscore_support(test_y, test_pred, average='macro')\n",
    "    \n",
    "    prec_temp+=precision\n",
    "    rec_temp += recall\n",
    "    f1_temp += f_value\n",
    "    \n",
    "    print(f'Fold {i+1} Eval...   | ACC : {temp_res} | PREC : {precision} | REC : {recall} | F1-SCORE : {f_value} | SUPP : {support}')\n",
    "\n",
    "res = acc_temp/n_fold\n",
    "prec_res = prec_temp/n_fold\n",
    "rec_res = rec_temp/n_fold\n",
    "f1_res = f1_temp/n_fold\n",
    "\n",
    "print(f'Average Accuracy Score({n_fold} Times Evaluation) : {res}')\n",
    "print(f'Average Precision Score({n_fold} Times Evaluation) : {prec_res}')\n",
    "print(f'Average Recall Score({n_fold} Times Evaluation) : {rec_res}')\n",
    "print(f'Average F1 Score({n_fold} Times Evaluation) : {f1_res}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
