{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cee8057",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b6ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "## Random Forest Classiffier \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38984cba",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "152d3e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jenis</th>\n",
       "      <th>uraian</th>\n",
       "      <th>pertanyaan</th>\n",
       "      <th>opsi1</th>\n",
       "      <th>opsi2</th>\n",
       "      <th>opsi3</th>\n",
       "      <th>opsi4</th>\n",
       "      <th>kunci_jawaban</th>\n",
       "      <th>kategori</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Makna kata/istilah</td>\n",
       "      <td>Padi yang luas menguning adalah hasil tanam ya...</td>\n",
       "      <td>Makna kata jasa pada paragraf di atas adalah</td>\n",
       "      <td>Pelayanan yang terbaik bagi kita.</td>\n",
       "      <td>Manfaat yang melimpah bagi kita</td>\n",
       "      <td>Perbuatan yang berguna bagi orang lain</td>\n",
       "      <td>Jerih payah yang sangat menguntungkan</td>\n",
       "      <td>Perbuatan yang berguna bagi orang lain</td>\n",
       "      <td>Mudah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antonim/sinonim</td>\n",
       "      <td>Suara radio tetangga sebelah sangat keras pada...</td>\n",
       "      <td>Antonim kata keras pada kalimat tersebut adalah</td>\n",
       "      <td>pelan</td>\n",
       "      <td>lunak</td>\n",
       "      <td>kaku</td>\n",
       "      <td>kencang</td>\n",
       "      <td>pelan</td>\n",
       "      <td>Mudah</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Informasi tersurat teks</td>\n",
       "      <td>Pembiasaan Hidup Sehat Sejak KecilPola hidup s...</td>\n",
       "      <td>Bagaimana cara memenuhi gizi anak pada usia ba...</td>\n",
       "      <td>Menambah gizi anak seiring bertambahnya usia a...</td>\n",
       "      <td>Makan makanan bergizi, istirahat cukup, dan ol...</td>\n",
       "      <td>Mempunyai kekebalan yang baik terhadap seranga...</td>\n",
       "      <td>Pemenuhan gizi dengan pemberian ASI saat anak...</td>\n",
       "      <td>Pemenuhan gizi dengan pemberian ASI saat anak...</td>\n",
       "      <td>Sedang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Informasi tersirat teks</td>\n",
       "      <td>Mulai tahun 2016 kuota haji di Indonesssia dit...</td>\n",
       "      <td>Berdasarkan data kuota jumlah jamaah haji untu...</td>\n",
       "      <td>77</td>\n",
       "      <td>77.7</td>\n",
       "      <td>78</td>\n",
       "      <td>77,800</td>\n",
       "      <td>77</td>\n",
       "      <td>Sedang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Informasi tersurat teks</td>\n",
       "      <td>Kebiasaan makan makanan bergizi dengan kadar s...</td>\n",
       "      <td>Kalimat dalam paragraf di atas yang tidak padu...</td>\n",
       "      <td>Kebutuhan gizi anak akan semakin bertambah sei...</td>\n",
       "      <td>Kebutuhan gizi anak baru terpenuhi saat anak b...</td>\n",
       "      <td>Tubuh anak mudah terserang berbagai macam peny...</td>\n",
       "      <td>Pertumbuhan dan perkembangan anak akan semakin...</td>\n",
       "      <td>Tubuh anak mudah terserang berbagai macam peny...</td>\n",
       "      <td>Sedang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     jenis                                             uraian  \\\n",
       "0       Makna kata/istilah  Padi yang luas menguning adalah hasil tanam ya...   \n",
       "1          Antonim/sinonim  Suara radio tetangga sebelah sangat keras pada...   \n",
       "2  Informasi tersurat teks  Pembiasaan Hidup Sehat Sejak KecilPola hidup s...   \n",
       "3  Informasi tersirat teks  Mulai tahun 2016 kuota haji di Indonesssia dit...   \n",
       "4  Informasi tersurat teks  Kebiasaan makan makanan bergizi dengan kadar s...   \n",
       "\n",
       "                                          pertanyaan  \\\n",
       "0       Makna kata jasa pada paragraf di atas adalah   \n",
       "1    Antonim kata keras pada kalimat tersebut adalah   \n",
       "2  Bagaimana cara memenuhi gizi anak pada usia ba...   \n",
       "3  Berdasarkan data kuota jumlah jamaah haji untu...   \n",
       "4  Kalimat dalam paragraf di atas yang tidak padu...   \n",
       "\n",
       "                                               opsi1  \\\n",
       "0                 Pelayanan yang terbaik bagi kita.    \n",
       "1                                             pelan    \n",
       "2  Menambah gizi anak seiring bertambahnya usia a...   \n",
       "3                                                 77   \n",
       "4  Kebutuhan gizi anak akan semakin bertambah sei...   \n",
       "\n",
       "                                               opsi2  \\\n",
       "0                   Manfaat yang melimpah bagi kita    \n",
       "1                                             lunak    \n",
       "2  Makan makanan bergizi, istirahat cukup, dan ol...   \n",
       "3                                               77.7   \n",
       "4  Kebutuhan gizi anak baru terpenuhi saat anak b...   \n",
       "\n",
       "                                               opsi3  \\\n",
       "0            Perbuatan yang berguna bagi orang lain    \n",
       "1                                              kaku    \n",
       "2  Mempunyai kekebalan yang baik terhadap seranga...   \n",
       "3                                                 78   \n",
       "4  Tubuh anak mudah terserang berbagai macam peny...   \n",
       "\n",
       "                                               opsi4  \\\n",
       "0              Jerih payah yang sangat menguntungkan   \n",
       "1                                            kencang   \n",
       "2   Pemenuhan gizi dengan pemberian ASI saat anak...   \n",
       "3                                             77,800   \n",
       "4  Pertumbuhan dan perkembangan anak akan semakin...   \n",
       "\n",
       "                                       kunci_jawaban kategori  label  \n",
       "0            Perbuatan yang berguna bagi orang lain     Mudah      0  \n",
       "1                                             pelan     Mudah      0  \n",
       "2   Pemenuhan gizi dengan pemberian ASI saat anak...   Sedang      1  \n",
       "3                                                 77   Sedang      1  \n",
       "4  Tubuh anak mudah terserang berbagai macam peny...   Sedang      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Random Forest Classiffier #reading the data\n",
    "dataset = pd.read_csv('dataset.csv', header=0, engine='python')\n",
    "del dataset['No']\n",
    "dataset = dataset.dropna()\n",
    "dataset['kategori'] = dataset['kategori'].astype(\"category\")\n",
    "dataset['label'] = dataset['kategori'].cat.codes\n",
    "dataset = dataset.replace('\\n',' ', regex=True)\n",
    "dataset = dataset.replace('\\t',' ', regex=True)\n",
    "dataset = dataset.replace('\"',' \" ', regex=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b0d446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Makna kata/istilah Padi yang luas menguning ad...\n",
       "1    Antonim/sinonim Suara radio tetangga sebelah s...\n",
       "2    Informasi tersurat teks Pembiasaan Hidup Sehat...\n",
       "3    Informasi tersirat teks Mulai tahun 2016 kuota...\n",
       "4    Informasi tersurat teks Kebiasaan makan makana...\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = dataset['jenis'].map(str) + ' ' + dataset['uraian'].map(str)+ ' ' + dataset['pertanyaan'].map(str)+ ' ' + dataset['opsi1'].map(str)+ ' ' + dataset['opsi2'].map(str)+ ' ' + dataset['opsi3'].map(str)+ ' ' + dataset['opsi4'].map(str)+ ' ' + dataset['kunci_jawaban'].map(str)   # '0' refers to the review text\n",
    "train_y = dataset['label']\n",
    "\n",
    "df_final=[]\n",
    "\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe2b4f6",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43a4e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sastrawi in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sastrawi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7667f66",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a207a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua', 'ia', 'seperti', 'jika', 'jika', 'sehingga', 'kembali', 'dan', 'tidak', 'ini', 'karena', 'kepada', 'oleh', 'saat', 'harus', 'sementara', 'setelah', 'belum', 'kami', 'sekitar', 'bagi', 'serta', 'di', 'dari', 'telah', 'sebagai', 'masih', 'hal', 'ketika', 'adalah', 'itu', 'dalam', 'bisa', 'bahwa', 'atau', 'hanya', 'kita', 'dengan', 'akan', 'juga', 'ada', 'mereka', 'sudah', 'saya', 'terhadap', 'secara', 'agar', 'lain', 'anda', 'begitu', 'mengapa', 'kenapa', 'yaitu', 'yakni', 'daripada', 'itulah', 'lagi', 'maka', 'tentang', 'demi', 'dimana', 'kemana', 'pula', 'sambil', 'sebelum', 'sesudah', 'supaya', 'guna', 'kah', 'pun', 'sampai', 'sedangkan', 'selagi', 'sementara', 'tetapi', 'apakah', 'kecuali', 'sebab', 'selain', 'seolah', 'seraya', 'seterusnya', 'tanpa', 'agak', 'boleh', 'dapat', 'dsb', 'dst', 'dll', 'dahulu', 'dulunya', 'anu', 'demikian', 'tapi', 'ingin', 'juga', 'nggak', 'mari', 'nanti', 'melainkan', 'oh', 'ok', 'seharusnya', 'sebetulnya', 'setiap', 'setidaknya', 'sesuatu', 'pasti', 'saja', 'toh', 'ya', 'walau', 'tolong', 'tentu', 'amat', 'apalagi', 'bagaimanapun', 'dengan', 'ia', 'bahwa', 'oleh']\n"
     ]
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "more_stopword = ['dengan', 'ia','bahwa','oleh']\n",
    "stop_words_id = stop_factory.get_stop_words()+more_stopword\n",
    "stopword = stop_factory.create_stop_word_remover()\n",
    "print(stop_words_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5878a43",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497267c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4914</th>\n",
       "      <th>4915</th>\n",
       "      <th>4916</th>\n",
       "      <th>4917</th>\n",
       "      <th>4918</th>\n",
       "      <th>4919</th>\n",
       "      <th>4920</th>\n",
       "      <th>4921</th>\n",
       "      <th>4922</th>\n",
       "      <th>4923</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 4924 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  4914  \\\n",
       "0       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3       1     4     1     1     0     0     0     0     0     0  ...     0   \n",
       "4       0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "413     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "414     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "415     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "416     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "417     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "     4915  4916  4917  4918  4919  4920  4921  4922  4923  \n",
       "0       0     0     0     0     0     0     0     0     0  \n",
       "1       0     0     0     0     0     0     0     0     0  \n",
       "2       0     0     0     0     1     0     0     0     0  \n",
       "3       0     0     0     0     0     0     0     0     0  \n",
       "4       0     0     0     0     1     0     0     0     0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "413     0     0     0     0     0     0     0     0     0  \n",
       "414     0     0     0     0     0     0     0     0     0  \n",
       "415     0     0     0     0     0     0     0     0     0  \n",
       "416     0     0     0     0     0     0     0     0     0  \n",
       "417     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[418 rows x 4924 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words = stop_words_id)\n",
    "\n",
    "x_cv = vect.fit_transform(df_x)\n",
    "\n",
    "test = pd.DataFrame(x_cv.toarray())\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de5723",
   "metadata": {},
   "source": [
    "# Generate CSV Dataset for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e98b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for evauation successfully generated !\n"
     ]
    }
   ],
   "source": [
    "test['label'] = dataset['label']\n",
    "\n",
    "test.to_csv('dataset_eval_cv.csv', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Dataset for evauation successfully generated !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62993c8",
   "metadata": {},
   "source": [
    "# Train & Test Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e361c54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((355, 4924), (355,), (63, 4924), (63,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split Dataset into Train and Test Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_eval = dataset = pd.read_csv('dataset_eval_cv.csv', header=0, engine='python')\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(df_eval.drop('label', axis = 1), df_eval['label'], test_size=0.15, random_state=42)\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4333bb21",
   "metadata": {},
   "source": [
    "# Single Fold Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c077bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253968253968254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Machine Learning classifier\n",
    "model = RandomForestClassifier(n_estimators = 300)\n",
    "model.fit(train_x, train_y)\n",
    "# Train & Test Dataset Split\n",
    "test_pred = model.predict(test_x)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ce0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted y\n",
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66dd99ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Mudah       0.76      0.92      0.83        24\n",
      "      Sedang       0.80      0.62      0.70        13\n",
      "       Sulit       0.92      0.85      0.88        26\n",
      "\n",
      "    accuracy                           0.83        63\n",
      "   macro avg       0.83      0.79      0.80        63\n",
      "weighted avg       0.83      0.83      0.82        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_y, y_pred, target_names=['Mudah', 'Sedang', 'Sulit']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e85e65",
   "metadata": {},
   "source": [
    "# Machine Learning Classification Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69388a",
   "metadata": {},
   "source": [
    "## Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5772dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Eval...   | ACC : 0.7777777777777778 | PREC : 0.797420634920635 | REC : 0.7542735042735043 | F1-SCORE : 0.7632923659750671 | SUPP : None\n",
      "Fold 2 Eval...   | ACC : 0.7936507936507936 | PREC : 0.7881513788560266 | REC : 0.7660256410256411 | F1-SCORE : 0.7720874513327344 | SUPP : None\n",
      "Fold 3 Eval...   | ACC : 0.8253968253968254 | PREC : 0.847955950340242 | REC : 0.7938034188034188 | F1-SCORE : 0.806926406926407 | SUPP : None\n",
      "Fold 4 Eval...   | ACC : 0.7777777777777778 | PREC : 0.7931697931697932 | REC : 0.7425213675213675 | F1-SCORE : 0.7506306061737194 | SUPP : None\n",
      "Fold 5 Eval...   | ACC : 0.8095238095238095 | PREC : 0.8154589371980676 | REC : 0.7799145299145298 | F1-SCORE : 0.7892032819569051 | SUPP : None\n",
      "Fold 6 Eval...   | ACC : 0.8253968253968254 | PREC : 0.8083501683501684 | REC : 0.7916666666666666 | F1-SCORE : 0.7973856209150328 | SUPP : None\n",
      "Fold 7 Eval...   | ACC : 0.8253968253968254 | PREC : 0.8561808561808562 | REC : 0.7948717948717948 | F1-SCORE : 0.8068139400726188 | SUPP : None\n",
      "Fold 8 Eval...   | ACC : 0.7936507936507936 | PREC : 0.7881513788560266 | REC : 0.7660256410256411 | F1-SCORE : 0.7720874513327344 | SUPP : None\n",
      "Fold 9 Eval...   | ACC : 0.7936507936507936 | PREC : 0.806256109481916 | REC : 0.767094017094017 | F1-SCORE : 0.7763285024154589 | SUPP : None\n",
      "Fold 10 Eval...   | ACC : 0.7777777777777778 | PREC : 0.7787878787878788 | REC : 0.7532051282051282 | F1-SCORE : 0.7592592592592592 | SUPP : None\n",
      "Average Accuracy Score(10 Times Evaluation) : 0.7999999999999999\n",
      "Average Precision Score(10 Times Evaluation) : 0.807988308614161\n",
      "Average Recall Score(10 Times Evaluation) : 0.7709401709401709\n",
      "Average F1 Score(10 Times Evaluation) : 0.7794014886359938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "acc_temp = 0\n",
    "prec_temp = 0\n",
    "rec_temp = 0\n",
    "f1_temp = 0\n",
    "n_fold = 10\n",
    "\n",
    "for i in range(n_fold):\n",
    "    model = RandomForestClassifier(n_estimators = 300)\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    test_pred = model.predict(test_x)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    temp_res = accuracy_score(test_y, test_pred)\n",
    "    acc_temp+= temp_res\n",
    "    \n",
    "    precision, recall, f_value, support = precision_recall_fscore_support(test_y, test_pred, average='macro')\n",
    "    \n",
    "    prec_temp+=precision\n",
    "    rec_temp += recall\n",
    "    f1_temp += f_value\n",
    "    \n",
    "    print(f'Fold {i+1} Eval...   | ACC : {temp_res} | PREC : {precision} | REC : {recall} | F1-SCORE : {f_value} | SUPP : {support}')\n",
    "\n",
    "res = acc_temp/n_fold\n",
    "prec_res = prec_temp/n_fold\n",
    "rec_res = rec_temp/n_fold\n",
    "f1_res = f1_temp/n_fold\n",
    "\n",
    "print(f'Average Accuracy Score({n_fold} Times Evaluation) : {res}')\n",
    "print(f'Average Precision Score({n_fold} Times Evaluation) : {prec_res}')\n",
    "print(f'Average Recall Score({n_fold} Times Evaluation) : {rec_res}')\n",
    "print(f'Average F1 Score({n_fold} Times Evaluation) : {f1_res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad65850",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d43a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 2 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 3 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 4 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 5 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 6 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 7 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 8 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 9 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Fold 10 Eval...   | ACC : 0.6349206349206349 | PREC : 0.611111111111111 | REC : 0.6111111111111112 | F1-SCORE : 0.6054951405306016 | SUPP : None\n",
      "Average Accuracy Score(10 Times Evaluation) : 0.6349206349206348\n",
      "Average Precision Score(10 Times Evaluation) : 0.6111111111111109\n",
      "Average Recall Score(10 Times Evaluation) : 0.611111111111111\n",
      "Average F1 Score(10 Times Evaluation) : 0.6054951405306016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "acc_temp = 0\n",
    "prec_temp = 0\n",
    "rec_temp = 0\n",
    "f1_temp = 0\n",
    "n_fold = 10\n",
    "\n",
    "for i in range(n_fold):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    test_pred = model.predict(test_x)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    temp_res = accuracy_score(test_y, test_pred)\n",
    "    acc_temp+= temp_res\n",
    "    \n",
    "    precision, recall, f_value, support = precision_recall_fscore_support(test_y, test_pred, average='macro')\n",
    "    \n",
    "    prec_temp+=precision\n",
    "    rec_temp += recall\n",
    "    f1_temp += f_value\n",
    "    \n",
    "    print(f'Fold {i+1} Eval...   | ACC : {temp_res} | PREC : {precision} | REC : {recall} | F1-SCORE : {f_value} | SUPP : {support}')\n",
    "\n",
    "res = acc_temp/n_fold\n",
    "prec_res = prec_temp/n_fold\n",
    "rec_res = rec_temp/n_fold\n",
    "f1_res = f1_temp/n_fold\n",
    "\n",
    "print(f'Average Accuracy Score({n_fold} Times Evaluation) : {res}')\n",
    "print(f'Average Precision Score({n_fold} Times Evaluation) : {prec_res}')\n",
    "print(f'Average Recall Score({n_fold} Times Evaluation) : {rec_res}')\n",
    "print(f'Average F1 Score({n_fold} Times Evaluation) : {f1_res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa718f",
   "metadata": {},
   "source": [
    "## SVM Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85f9624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 2 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 3 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 4 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 5 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 6 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 7 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 8 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 9 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Fold 10 Eval...   | ACC : 0.6984126984126984 | PREC : 0.6687317620650953 | REC : 0.6623931623931624 | F1-SCORE : 0.6633986928104575 | SUPP : None\n",
      "Average Accuracy Score(10 Times Evaluation) : 0.6984126984126985\n",
      "Average Precision Score(10 Times Evaluation) : 0.6687317620650954\n",
      "Average Recall Score(10 Times Evaluation) : 0.6623931623931625\n",
      "Average F1 Score(10 Times Evaluation) : 0.6633986928104576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "acc_temp = 0\n",
    "prec_temp = 0\n",
    "rec_temp = 0\n",
    "f1_temp = 0\n",
    "n_fold = 10\n",
    "\n",
    "for i in range(n_fold):\n",
    "    model = SVC(kernel='linear')\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    test_pred = model.predict(test_x)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    temp_res = accuracy_score(test_y, test_pred)\n",
    "    acc_temp+= temp_res\n",
    "    \n",
    "    precision, recall, f_value, support = precision_recall_fscore_support(test_y, test_pred, average='macro')\n",
    "    \n",
    "    prec_temp+=precision\n",
    "    rec_temp += recall\n",
    "    f1_temp += f_value\n",
    "    \n",
    "    print(f'Fold {i+1} Eval...   | ACC : {temp_res} | PREC : {precision} | REC : {recall} | F1-SCORE : {f_value} | SUPP : {support}')\n",
    "\n",
    "res = acc_temp/n_fold\n",
    "prec_res = prec_temp/n_fold\n",
    "rec_res = rec_temp/n_fold\n",
    "f1_res = f1_temp/n_fold\n",
    "\n",
    "print(f'Average Accuracy Score({n_fold} Times Evaluation) : {res}')\n",
    "print(f'Average Precision Score({n_fold} Times Evaluation) : {prec_res}')\n",
    "print(f'Average Recall Score({n_fold} Times Evaluation) : {rec_res}')\n",
    "print(f'Average F1 Score({n_fold} Times Evaluation) : {f1_res}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
